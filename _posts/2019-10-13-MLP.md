---
layout: post
title: Multi-layer Perceptron Description
categories: [AI]
tags: [MLP, POSTECH]
---
# Multi-layer Perceptron

## Objective 

* 본 과제에서는 Multi-Layer Perceptron을 구현하여 Two Moon Dataset 과 Iris Dataset 들을 학습하고 결과를 산출한다. 이를 통해 C++의 다양한 Class 기법을 연습한다

## Background

> Perceptron, Gradient Descent, Multi-Layer Perceptron Error, backpropagation

### Perceptron

* Percetron은 Neural Network의 가장 기본 단위이다.

* 수상돌기를 통해 들어온 다수의 신호($$x$$)를 입력으로 받아 *변조($$\text{activation } \sigma$$)*하여 일정 threshold를 넘기는 경우, 신호를 출력($$\hat{y}$$)하는 구조를 갖는다.

* Perceptron: **$$\hat{y} = \sigma(\Sigma{w_ix_i+b}) = \sigma(WX+b)$$**

  > * 입력(feature): $$X=(x_1,x_2,...,x_n)$$
  >
  > * 출력 : $$\hat{y}$$
  >
  > * Model Parameter
  >   * 가중치: $$W = (w_1,w_2,...,w_n)^T$$
  >   * bias: $$b$$
  >
  > 

* $$\sigma(x) = \frac{1}{1+e^{-x}}$$

  > sigmoid function의 값은 0에서 0.5, 그리고 음수와 양수일 때 각각 0.5보다 작고
  > 0.5보다 큰 값을 가지므로 0.5를 기준으로 True와 False로 나누는 activation에 적합한 함수이다.

### Gradient Descent

> Perceptron을 학습하는 방법은 Gradient Descent 방법을 사용해야한다.

* Loss Function 목적 함수

  * Perception의 결과값과 우리가 원하는 정답과의 차이를 설명해주는 함수.

  * 정답과 거리가 멀면 큰 값을, 가까우면 작은 값을 출력하여주는 함수이다.

  * 가장 간단한 함수가 Mean Square Error이다

    > **$$\text{loss function}: L(y,\hat{y}) = \frac{(\hat{y}-y^2)}{2}$$**

    * **y는 Data 실제 레이블(정답**). 즉, 목적 함수의 값이 0에 가까워질수록 정답에 가까워진다. 

  * 이때, 손실 함수(Loss Function)의 값을 최소로 하는 *최적의 해*를 구하기 위해서는 손실 함수의 **Gradient**를 살펴볼 필요가 있다. 

* Gradient Descent

  > 그림 참고

  * 그림을 보면, Gradient는 특정 지점(그림의 initial weight)의 tangential slope을 나타낸다
  * 이때 Model Parameter를 Gradient Negative 방향으로 업데이트를 한다면, 이것을  loss function 값을 최소로 갖게 하는 방법이라는 것을 짐작할 수 있다.
  * 이런 과정을 **"학습"**이라고 한다
    * Model Parameter을 Gradient가 Descent하게 Update하여 loss function의 값이 최소로 갖게 하는 것
  * 자 그럼 이제, gradient descent를 하기 위해 모델의 parameter를 줄일 수 있는 방법을 구하자

### Model Parameter 

> Model Parameter
>
> - 가중치: $$W = (w_1,w_2,...,w_n)^T$$
> - bias: $$b$$

* Chain Rule을 통해서 각 Parameter에 대한 손실함수의 미분 값을 구한다

* $$a =\Sigma_iw_ix_i+b$$라고 정의 할때, **Gradient**는 다음 방법으로 구한다

  > * $$a =\Sigma_iw_ix_i+b$$
  > * L: loss function $$\text{loss function}: L(y,\hat{y}) = \frac{\hat{y}-y^2}{2}$$
  > * $$\sigma(a) = \frac{1}{1+e^{-a}}$$
  > * $$\hat{y}$$=$$\sigma(XW+b)$$

$$
\frac{𝜕L}{𝜕\hat{y}}=\hat{y}-y
$$

$$
\frac{𝜕L}{𝜕a}=\sigma(a)(1-\sigma(a))
$$

$$
\frac{𝜕a}{𝜕w_i}=x_i,\frac{𝜕a}{𝜕b}=1
$$

$$
∴\frac{𝜕L}{𝜕w_i}=\frac{𝜕a}{𝜕\hat{y}}\times \frac{𝜕a}{𝜕w_i}=(\hat{y}-y)\sigma(1-\sigma(a))x_i
$$

$$
∴\frac{𝜕L}{𝜕b}=\frac{𝜕L}{𝜕\hat{y}}\times \frac{𝜕\hat{y}}{𝜕a}\times \frac{𝜕a}{𝜕b}=(\hat{y}-y)\sigma(1-\sigma(a))
$$



* 위에서 결과적으로 나온 **Gradient** 식의 값이 최소값을 갖도록하는 **Model Parameter**을 구해야 한다. 

* 문제는, 이대로 Gradient 식을 그대로 사용하면, 수렴하지 않고 **진동**을 한다

  > 고로, Learning Rate $$\eta$$ 라는 **hyper-parameter**을 설정한다

### Hyper-Parameter

* $$\eta$$ 값이 너무 작으면 수렴하는데 오랜사간이 걸리고, 너무 크면 발산하기 때문에 적당한 값을 가져야 한다

  > Parameter가  update하기 위해서  Old Value에서 value의 Gradient을 Hyper-Parameter와 곱해서 뺀 값으로 설정한다

$$
w_i^{new} = w_i^{old}-\eta\frac{𝜕L}{𝜕w_i^{old}}
$$

$$
b^{new} = b^{old} - \eta\frac{𝜕L}{𝜕b^{old}}
$$



> 사실 paramter을 구하기 위해 Gradient 함수를 Chain Rule이 아닌 더 쉬운 방법으로 구할 수 있다. 다만, 뒤에 나올 **Error Backpropagation** 때문이다

* 더 편한 계산<sub>(Multi-Layer을 사용하기 위함도 있음)</sub> 을 위해 **Vector**을 사용하여 축약된 Gradient식을 사용 할 것이다.($$\nabla$$는 편미분 기호를 대시 사용한다)

  > 편미분??

$$
\nabla_{\hat{y}}L = \hat{y}-y
$$

$$
\nabla_{\hat{y}}L =\sigma(a)(1-\sigma(a))
$$

$$
\nabla_{w}a=X^T, \nabla_ba = 1
$$

$$
∴\nabla_wL=\nabla_{\hat{y}}L\times\nabla_a\hat{y}\times\nabla_wa=(\hat{y}-y)\sigma(a)(1-\sigma(a))X^T
$$

$$
∴\nabla_bL=\nabla_{\hat{y}}L\times\nabla_a\hat{y}\times\nabla_ba=(\hat{y}-y)\sigma(a)(1-\sigma(a))
$$

> T는 Matrix의 transpose이다....가로를 새로로, 세로를 가로로

* 다음 식은 $$\nabla$$를 적용한 hyper-paramter이다

$$
  w^{new} = w^{old}-\eta\nabla_{w^{old}}L
$$

$$
  b^{new} = b^{old} - \eta\nabla_{b^{old}}L
$$

  

> 여기까지는 올바른 Hyper Parameter을 구하기 위하여 Gradient을 구하는 이야기를 하였다. 이제 Perceptron의 개념이 확장된 **Multi-Layer Perceptron**의 개념에 대해 이야기 하자

### Multi-Layer Perceptron

> * 간단하게, Multi-Layer을 사용하는 이유와 그 구성에 대해서 이야기를 하자
>  * Muli-Layer Perception은 여러개의 Perception을 stacking한 것을 말한다.  Stacking을 하기 때문에 출력값이 Scalar가 아닌 Vector 형태로 나와야 하는 것이다.
>   * 또한, Perception은 linear function이기 떄문에, nonlinear한 정보를 classify하여서 Multi-Layer Perception을 사용하는 것이 유리하다.

* 그림 참조

  > 각 원은 하나의  perception을 의미한다. 
  >
  > * W와 b는 parameter가 된고, Hiddent Layer는 계층적인 관점에서 Perception의 집합이라고 할 수 있다

* **Hidden Layer 1**의 수식이다

  * $$m$$은 hidden layer의 perceptron 개수이다

    $$
    h_{1i}=\sigma(XW_{1i}+b_{1i}), i = \{1,....m\}
    $$

    $$
    h_1=(h_{11},h_{_12},...h_{1m})
    $$

    

  > $$h_n$$은 hidden layer n을 나타낸다

* Hidden Layer 1의 출력은 Hidden Layer 2의 입력으로 들어간다. 다음식은, **Hidden Layer 2**의 수식이다

  * $$m$$은 역식 hidden layer 2의 perceptron 개수이다

    $$
    h_{2j}=\sigma(h_1W_{2j}+b_{2j}),j=\{1,...j\}
    $$

* **Matrix Multiplication**을 사용하여 표현하면 더 간결하게 표현이 가능하다

* **Hidden Layer 1**

  > * $$W_{1nm}$$이다, 즉, 가장 앞의 1은 $$W_1$$을 의미하는 것이다.$$b$$도 동일하다....Don't Confuse
  > * $$n$$은 input 값의 **갯수이다**

$$
W_1=\begin{bmatrix}
  W_{111} & \cdots & W_{1n1}\\
  \vdots & \ddots &\vdots \\
  W_{11m} & \cdots & W_{1nm}\\
  \end{bmatrix}
  =
  \begin{bmatrix}
  W_{11} & \cdots & W_{1m}
  \end{bmatrix}
$$

$$
b_1=\begin{bmatrix}
b_{11} & \cdots & b_{1m}
\end{bmatrix}
$$

$$
h_1 =\begin{bmatrix}
\sigma(XW_{11}+b_{11}) & \cdots & \sigma(XW_{1m}+b_{1m})
\end{bmatrix}
=\sigma(XW_{1}+b_{1})
$$

* **Hidden Layer 2**도 같은 방법으로 표현한다

$$
\hat{y}=h_2=\sigma(h_1W_2+b_2)
$$

$$
\hat{y}=(\hat{y_1},\hat{y_2},...\hat{y_l})
$$



* **레이블 $$y$$**의 표현 법

  * 앞에서 $$y$$는 data의 실제 레이블(정답)이라고 했다
  * 이 $$y$$를 표현 할때, *one-hot encoding*으로 사용하여 표현이 가능하다.
  * $$y$$가 총 10의 길이를 가지고 있을 때, 3번 class의 lable을 가진다고 하면 $$y$$는 다음과 같은 형태를 갖는다

  $$
  y=(0,0,1,0,0,0,0,0,0,0)
  $$

  > 해석을 하면, lable을 갖고 있을 수 있는 $$y$$의 3번째 class에 lable이 있다는 말이다??...그래서 비교 할 수 있다는 말??

  * 최종 결과값인 $$\hat{y}$$에서 가장 높은 값을 추출하면 그 값과  lable을 비교 할 수 있다. 
  * 비교할때는, 가장 높은 값, argmax인 $$\hat{y}$$와 lable과 비교한다

> lable $$y$$과 $$\hat{y}$$의 이해를 돕기 위해서
>
> * 그림 5를 참고하라. Input은 hidden layer을 통해서 output을 만들어 낸다.
>   * hidden layer 안은 perceptron으로 구성이 되어 있고,  input 값과 output 값의 개수를 설정할 수 있기 떄문에, hidden layer 1에서는 다수의 output을 만드는데, 왜 hidden layer 2 는 하나의  output만 만드냐는 질문은 하지 말자
> * 이때, hidden layer을 통해서 만든 값, 즉, output이 $$\hat{y}$$이고, $$y$$는  lable로써 정답이다.(주어진 값인가??)
> * 고로, $$\hat{y}$$와  $$y$$는 같은 성질(?)의  output이기 떄문에 비교가 가능하다

* **Classification**
  * classification을 통해서 $$\hat{y}$$를 출력한다고 한다.
  * 즉,  Hidden Layer들을 말하는 것이다??

### Error Backpropagation

> * 잠깐 정리를 해보자
> * 지금 까지는 Parceptron의 개념과, 올바른 Parceptron, 즉, model paramter를 구하기 위해 multil-layer의 개념을 배웠다. Loss Functionr과 Percentron 식으로 부터 Model Parameter을 구하는 방법은 배웠으나, **어떻게 하면 *좋은* Model parameter를 구하는지, 즉 Update를 하여 구하는 방법을 아직 안배웠다.** 
> * *좋은* Model Parameter을 구하는 방법을 **학습 방법**이라고 이야기 할 수 있다. **Error Backpropagation**을 통해서 학습 방법에 대한 solution에 대해 배울 것 이다.  (Gradient 함수를 Chai Rule로 푼 이유)

* Chain Rule을 사용하여 각 계층에 있는 parameter의 Gradient를 구하여 뒤에서 부터 **순차적으로** Update하는 방법이다.

  * Chain Rule을 통해서 뒤에서 부터 순차적으로 구하는 이유는,  Multi-Layer Perception의 정의는 위에서 배운 것 같이 명확하게 내릴 수 있지만, 게층을 쌓게 되면 Loss Function에 대한 마땅한 학습을 할 수 없기 때문이다.
  * 즉, 학습을 실행하기 위해서 이다

  > Parameter을 통해 Gradient를 구하는 것이다.
  >
  > 그림 5, 처럼 Hidden Layer는 2개 분아다.(마지막 Hidden Layer는 2번쨰 것 이다)

  $$
  \text{Given: }a_2 = h_2W_2+b_2
  $$

  $$
  L(y,\hat{y})=(\hat{y}-y)^2
  $$

  $$
  \nabla_{\hat{y}}L=\hat{y}-y
  $$

  $$
  \nabla_{a_2}\hat{y}=\sigma(a_2)(1-\sigma(a_2))
  $$

  $$
  \nabla_{w_2}a_2=h_1^T,\nabla_{b_2}a_2=1=(1,....,1)^T
  $$

  > 여기서 1은 vector이다

  $$
  ∴\nabla_{w_2}L=\nabla_{\hat{y}}L\odot\nabla_{a_2}\hat{y}\times\nabla_{w_1}a_2=(\hat{y}-y)\odot\{\sigma(a_2)(1-\sigma(a_2))\}\times h_{1}^T
  $$

  $$
  ∴\nabla_{b_2}L=\nabla_{\hat{y}L}\times \nabla_{b}a_2=(\hat{y}-y)\odot\{\sigma(a_2)\{1-\sigma(a_2\}\}\times 1
  $$

  * 위의 식사용하여, **Hidden Layer 2의 Parameter을 Update** 하였다
    $$
    W_2^{new}=W_{2}^{old}-\eta\nabla_{w_2^{old}}L
    $$

    $$
    b_2^{new}=b_2^{old}-\eta\nabla_{b_2^{old}}L
    $$

    > * 위 식에서는 주어진 parameter를 Hidden Layer 2에 기준에서 새로운 parameter로 업데이트를 하였다.
    >
    > * Hyper-Parameter를 구할때와 같은 방법이다. 하지만 여기서는 Hidden Layer 2에서 부터 거꾸로 가기 때문에, 이제 우리는 Hidden Layer 1에 대한 parameter을 구할 수 있다

  * **Hidden Layer 1의 Parameter을 Update** 해주어야 한다.

    * Parameter을 Update하기 위해서는 $$h_1$$에 대한 Gradient를 chain rule을 사용하여  $$\nabla_{w_1}{L}$$와 $$\nabla_{b_1}L$$를 구해야 한다.
    * $$a_2$$에 대한 Gradient까지 구한 부분에 적용 해야  $$\nabla_{w_1}{L}$$와 $$\nabla_{b_1}L$$을 구할 수 있는데, 그러기 위해서는  $$\nabla_{h_1}a_2$$을 알아야 한다.

$$
\nabla_{h_1}a_2=W_{2}^T
$$

$$
\nabla_{h_1}L = \nabla_{\hat{y}}L\odot\nabla_{a_2}{\hat{y}} \times \nabla_{h_1}a_2=(\hat{y}-y)\odot\{\sigma(a_2)\{1-\sigma(a_2)\}\}\times W_2^T
$$

> $$\nabla_{h_1}a_2$$을 구했으니,  $$\nabla_{w_1}{L}$$와 $$\nabla_{b_1}L$$ 구하여 Hidden Layer 1의 Parameter을 Update하자

$$
\nabla_{a_1}h1=\sigma(a_1)(1-\sigma(a_1))
$$

$$
\nabla_{w_1}a_1=X^T, \nabla_{b_1}a_1= 1=(1,....,1)^T
$$

$$
\nabla_{W_1}L=\nabla_{h_1}L\odot\nabla_{a_1}h_1\times\nabla_{w_1}a_2
$$

$$
\nabla_{b_1}L=\nabla_{h_1}L\odot\nabla_{a_1}h_1\times\nabla_{b_1}a_2
$$

$$
W_{1}^{new}=W_{1}^{old}-\eta\nabla_{w_1^{old}}{L}
$$

$$
b_1^{new}=b_1^{old}-\eta\nabla_{b_1^{old}}L
$$

### Multi-Data

* 지금까지는 하나의 Data에 대해서만 설명을 하였었다. 만약 **다수의 data**에 대한 학습이라면, Gradient의 합 또는 평균을 사용하여 업데이트를 하면된다.  다수의 data를 표현하기 위해서 다음과 같이 데이터를 표기한다

  * 만약, 합을 사용한다면, 평균을 사용할때에 비해서 **learning rate**조정을 신경 써야 한다. 

  $$
  X^i, i =\{1,2,....,N\}
  $$

  * 이 표현에서 $$i$$는 super script라고 하는데, $$i$$번쨰 data를 뜻한다

* super script를 적용하여, **손실 함수**를 나타내면 다음과 같은 식을 얻는다

  * 출력과 레이블(정답)에도 같은 Notation을 적용한 것이다

$$
L(y,\hat{y})=\Sigma_{i=1}^N(\hat{y}^i-y^i)^2
$$

### Learning & Data

* 데이터 크기가 큰 이미지 데이터 등은 모든 데이터를 한번에 업데이트 하기가 힘들다.
* 고로 **Mini Batch**라는 개념을 적용한다.
  * 데이터의 일부를 iterative하게 학습하는 것. 
* 모델을 학습할때,  **epoch**돌면서 한다
  * 한 데이터 세을 전부 사용하여 학습하는 iteration을 뜻 한다
* 학습 시, Data는 **Train,validation, test**로 나누어 사용한다
  *  **Train Data** 은 학습을 위해 사용된다.
  *  **Validation Data**은 학습 과정을 검증하는데, 사용되는데, 학습에 사용이 되지 않았기 때문에 가능하다. 
  *  **Test Data** 모델을 평가하기 위한 데이터로 보통 레이블을 공개하지 않고 공정한 모델 평가에 사용된다.

## Program Explaination

### Goal

* 그림 6은, **Two Moon Dataset**이다.
  * 이 그림에서는 non-linear한 2-feature(2개의 input), 2-class(2개의 output) dataset을 볼 수 있다. 
* 그림에 주어진 data를 학습시킬 수 있는 **classifier**를 학습시키고, **verify**하는 코드를 작성하여라.

### Given

* 아래 **인자**는 cmd를 통해서 직접 입력을 받게 되는 code이다

  * dataset_type[str] -> two moon 또는 iris **데이터를 결정하는 인자**
  * feature_num[int] -> 입력 데이터의 **feature 개수**
  * class_num[int] -> 분류하고자 하는 **클래스 개수**
  * hidden_layer_num[int] -> **hidden layer의 개수**
  * hidden_layer_neurons[str] -> 각 hidden layer의 **뉴런의 개수**. string으로 받아 int 형식의
    array로 변환하여 사용하여야 함 ex) “10 10 10”  ->  [10, 10, 10]
  * epochs[int] -> **학습 횟**수 (epoch)
  * learning_rate[float] -> **learning rate 수치**
  * train_data_dir[str] -> **학습 데이터 파일 위치**
  * train_data_num[int] -> **학습 데이터 개수**
  * validation_data_dir[str] -> **validation 데이터 파일 위치**
  * validation_data_num[int] -> **validation 데이터 개수**
  * test_data_dir[str] -> **test 데이터 파일 위치**
  * test_data_num[int] -> **test 데이터 개수**
  * test_output_dir[str] -> test 데이터를 통해 얻은 결과 **출력 경로**

* Class

  * Layer

    | V or M | name                       | type       | Description                                                  |
    | ------ | -------------------------- | ---------- | ------------------------------------------------------------ |
    | V      | in_dimentsion              | int        | 입력 차원                                                    |
    | V      | out_dimension              | int        | 출력 차원                                                    |
    | V      | weight                     | float\[][] | 파라미터                                                     |
    | V      | bias                       | float\[]   | 파라미터                                                     |
    | V      | input                      | float\[][] | forward 함수에서 받은 입력을 저장(Backward에서 사용)         |
    | V      | output                     | float\[][] | 함수에서 받은 입력을 저장(Backward에서 사용)                 |
    | M      | forward(float\[][])        | float\[][] | 입력을 받아 출력 값을 return                                 |
    | M      | backward(float\[][],float) | float\[][] | 입력 값을 통해 얻은 값과 이전 gradient 값을 통해 weight와 전달할 Gradient를 출력한다 |

  * Loss

    | V or M | Name                | Type       | Descroption                                                  |
    | ------ | ------------------- | ---------- | ------------------------------------------------------------ |
    | V      | logit               | float\[][] | 신경망의 최종 결과 값 (forward에서 입력 받아 저장)           |
    | V      | label               | float\[][] | forward에서 입력 받아 저장                                   |
    | M      | forward(float\[][]) | float\[][] | logit과 label을 입력 받아 손실 함수 값을 출력                |
    | M      | backward(void)      | float\[][] | 다음 layer에 전달할 Gradient를 logit과 label을 사용하여 출력 |

  * Dataloader

    | V or M | Name        | Type       | Description                                                  |
    | ------ | ----------- | ---------- | ------------------------------------------------------------ |
    | V      | file_dir    | string     | 데이터 파일 경로                                             |
    | V      | mode        | string     | train, validation,test 모드를 지정                           |
    | V      | feature_num | int        | data의 feature 개수(차원)                                    |
    | V      | class_num   | int        | 분류할 클래수 개수                                           |
    | V      | data_num    | int        | 데이터 개수                                                  |
    | V      | data        | float\[][] | 학습 data                                                    |
    | V      | lable       | float\[][] | test 모드에서는 사용하지 않음                                |
    | M      | read(void)  | void       | 데이터를 읽어와서 data와 label에 각각 저장함 (test mode에서는 label에 데이터를 저장하지 않음) |

  * Mlp (Multi-Layer Perceptron)

    | V or M | Name                     | Type       | Description                                                |
    | ------ | ------------------------ | ---------- | ---------------------------------------------------------- |
    | V      | layer                    | Layer[]    | Layer 오브젝트 array-hidden layer 개수에 따라 길이 변동    |
    | V      | loss                     | Loss       | Loss 오브젝트                                              |
    | V      | train_dataset            | Dataloade  | train에 사용할 Dataloader 오브젝트                         |
    | V      | train_data               | float\[][] | train_dataset에서 얻은 데이터를 저장                       |
    | V      | train_label              | float\[][] | train_dataset에서 얻은 레이블 저장(one_hot)                |
    | V      | validation_dataset       | Dataloader | validation에 사용할 dataloader오브젝트                     |
    | V      | validation_data          | float\[][] | validation_dataset에서 얻은 데이터를 저장                  |
    | V      | validation_label         | float\[][] | validation_dataset에서 얻은 레이블 저장(one_hot)           |
    | V      | epochs                   | int        | epoch                                                      |
    | v      | learning_rate            | float      | learning rate                                              |
    | M      | read_dataset(Dataloader) | void       | 데이터를 읽어와서 data와 label에 각각 저장 함              |
    | M      | add_layer(layer)         | void       | layer에 Layer 오브젝트를 추가함                            |
    | M      | visulaize_layer(void)    | void       | layer 계층 구조를 출력                                     |
    | M      | train(void)              | void       | 각 epoch마다 loss와 정확도를 출력                          |
    | M      | validation(void)         | void       | validation set에 대해서 loss와 정확도를 출력               |
    | M      | predict(Dataloader,str)  | void       | 입력한 Dataloader(test임)의 출력 결과를 텍스트 파일에 저장 |

### Condition

* 각 dataset에 대해서 학습이 잘되는 hyper-parameter(epochs,learning-rate, hidden layer 층수, neuron의 개수 등) 를 찾는 실험에 대한 과정 및 결과를 보고서에 제출해야 함. 필수 실험은 다음과 같다

| Epochs | Learning Rate ($$\eta$$) | Hidden Layer 개수 | Neuron 개수(Perceptron) |
| ------ | ------------------------ | ----------------- | ----------------------- |
| 100    | 0.01                     | 1                 | 10                      |
| 500    | 0.05                     | 2                 | 10,10                   |
| 1000   | 0.01                     | 3                 | 30,100,30               |
| 1000   | 0.03                     | 2                 | 100,100                 |

* 위 조건에 따라 과정과 결과를 보고서에 기입하고 자신이 찾은 최적의 값을 찾는 과정과 결과를 보고서에 작성해 함
* 학습한 네트워크로 각 dataset에 존재하는 test dataset(정답 레이블이 없는)에 대해 [Test 결과 예시]와 같은 형식으로 출력한 텍스트 파일을 과제 제출 시 소스코드와 함꼐 제출해야 함

---

### Ref

* [LOVITxDATA SCIENCE]([https://lovit.github.io/machine%20learning/2018/04/27/synthetic_dataset/](https://lovit.github.io/machine learning/2018/04/27/synthetic_dataset/))
  * soydaya, 복잡한 인공 데이터 생성을 위한 함수들.....**Skit-Learn**
* [편미분과 Gradient의 기하학적 의미](https://www.youtube.com/watch?v=bUNqn1G1O7E)
* [Khan: ChainRule](https://www.khanacademy.org/math/ap-calculus-ab/ab-differentiation-2-new/ab-3-1a/v/chain-rule-introduction)
* [Matrix의 기본 지식](http://researchhubs.com/post/maths/fundamentals/basic-of-matrix.html)
* [하다마드 곱: $$\odot$$](https://en.wikipedia.org/wiki/Hadamard_product_(matrices))
* [Matrix의 곱]([https://ko.wikipedia.org/wiki/%ED%96%89%EB%A0%AC_%EA%B3%B1%EC%85%88](https://ko.wikipedia.org/wiki/행렬_곱셈))
* [1-07. Multi Layer Perceptron 총정리](